重建干净图像的 MSE 损失函数，我们可以使用 PyTorch 自带的均方误差损失函数 F.mse_loss 实现。在这个损失函数中，我们需要传入两个参数：

clean_features：使用加雾图像的特征向量进行解码得到的重建干净图像；
gt：原始的干净图像。
这两个参数都是 PyTorch 的 Tensor 对象。具体实现如下
import torch.nn.functional as F

mse_loss = F.mse_loss(clean_features, gt)


接下来是重建噪声图像的 BCE 损失函数。在这个损失函数中，我们需要传入两个参数：

noise_recon：使用噪声图像的特征向量和加雾图像的特征向量进行解码得到的重建噪声图像；
mask：一个二值掩码，用于指示哪些像素是噪声，哪些像素是信号。
这两个参数都是 PyTorch 的 Tensor 对象。具体实现如下：
# 对噪声重建进行阈值化，以分离噪声和信号
threshold = 0.05
noise_mask = (noise_recon > threshold).float()

# 计算重建噪声图像与真实噪声图像之间的 BCE 损失
bce_loss = F.binary_cross_entropy_with_logits(noise_recon, mask, reduction='none')
noise_loss = (bce_loss * noise_mask).mean()

在实现中，我们首先对重建噪声图像进行了阈值化操作，将所有大于阈值的像素都认为是噪声，其余像素都认为是信号。
然后，我们使用 PyTorch 自带的二元交叉熵损失函数 F.binary_cross_entropy_with_logits 计算重建噪声图像与真实噪声图像之间的交叉熵损失。
由于阈值化操作可能会将一些本来属于噪声的像素误判为信号，因此我们在计算损失时，只对阈值化之后的噪声像素进行损失计算，而对信号像素不计入损失。最后，我们将所有噪声像素的损失求平均值，作为重建噪声图像的损失。


# 假设原始干净图像和加了雾的图像已经加载为名为 gt 和 noise_img 的 Tensor 对象
# 在训练时，我们需要将 total_loss 作为损失函数反向传播，更新模型的参数。在测试时，我们只需要使用 clean_recon 作为重建的干净图像，而不需要使用 noise_recon。
# 将 gt 和 noise_img 输入到模型中，得到解码出的特征向量
clean_features, noise_features = model(gt, noise_img)

# 使用 clean_features 进行重建干净图像的解码，并计算 MSE 损失
clean_recon = model.decode_clean(clean_features)
mse_loss = F.mse_loss(clean_recon, gt)

# 使用 clean_features 和 noise_features 进行重建噪声图像的解码，并计算 BCE 损失
noise_recon = model.decode_noise(clean_features, noise_features)
bce_loss = model.calc_noise_loss(noise_recon, mask)

# 计算总损失
total_loss = mse_loss + bce_loss


# 这个函数接受三个参数：
#
# model: 训练好的模型；
# test_loader: 测试集的数据加载器；
# device: 执行模型推断的设备（CPU 或 GPU）。
# 函数首先将模型设置为评估模式（model.eval()），这会关闭模型中的 Dropout 和 BatchNorm 层，从而保证模型的输出具有确定性。然后，函数遍历测试集中的所有样本，并依次计算每个样本的损失。最后，函数输出测试集上的平均损失。
def test(model, test_loader, device):
    model.eval()
    with torch.no_grad():
        clean_loss_total = 0
        noise_loss_total = 0
        for i, data in enumerate(test_loader):
            noise, haze, gt = data
            noise, haze, gt = noise.to(device), haze.to(device), gt.to(device)
            clean_loss, noise_loss = model(noise, haze, gt)
            clean_loss_total += clean_loss.item()
            noise_loss_total += noise_loss.item()

        clean_loss_avg = clean_loss_total / len(test_loader)
        noise_loss_avg = noise_loss_total / len(test_loader)

        print('Test set: Clean loss: {:.4f}, Noise loss: {:.4f}'.format(
            clean_loss_avg, noise_loss_avg))

可以将一张图片裁剪成多个样本送入网络训练。这种方法通常被称为数据增强（data augmentation），
通过对原始图像进行变换或处理，生成多个新的样本，从而扩大数据集并提高模型的泛化性能。
将图像裁剪成多个样本可以增加数据集的大小，同时也可以让模型学习到不同位置的特征，提高模型的鲁棒性。

在裁剪时，需要注意裁剪后的样本应该包含足够的信息以便于网络训练，例如不应该将人物的脑袋或者物体的重要部分裁剪掉。
此外，应该确保裁剪后的样本与原始图像的宽高比例相同，以避免变形引起的误差。



#返回一个CUDA设备上的生成器
def get_generator():
    global operation_seed_counter  #定义一个全局变量，用于生成操作的种子
    operation_seed_counter += 1
    g_cuda_generator = torch.Generator(device="cuda")
    g_cuda_generator.manual_seed(operation_seed_counter)
    return g_cuda_generator

#用于将输入张量x进行空间到深度的转换，再一定程度上增加网络的非线性容量，处进行信息的流动和特征的重用
def space_to_depth(x, block_size):
    n, c, h, w = x.size()  #获取张量x的维度信息
    unfolded_x = torch.nn.functional.unfold(x, block_size, stride=block_size)  #使用unfold函数对输入张量进行展开操作，将图像歌城block*block的块
    return unfolded_x.view(n, c * block_size**2, h // block_size,
                           w // block_size)   #实现空间到深度的转换。

#为给定图像生成一对掩码
def generate_mask_pair(img):
    # prepare masks (N x C x H/2 x W/2)
    n, c, h, w = img.shape
    print("img.shape:{}".format(img.shape))
    # h,w,n=img.shape
    #创建bool类型张量存储掩码
    mask1 = torch.zeros(size=(n * h // 2 * w // 2 * 4, ),
                        dtype=torch.bool,
                        device=img.device)
    mask2 = torch.zeros(size=(n * h // 2 * w // 2 * 4, ),
                        dtype=torch.bool,
                        device=img.device)
    # prepare random mask pairs
    idx_pair = torch.tensor(
        [[0, 1], [0, 2], [1, 3], [2, 3], [1, 0], [2, 0], [3, 1], [3, 2]],
        dtype=torch.int64,
        device=img.device)
    #创建张量存储随机生成的索引
    rd_idx = torch.zeros(size=(n * h // 2 * w // 2, ),
                         dtype=torch.int64,
                         device=img.device)
    torch.randint(low=0,
                  high=8,
                  size=(n * h // 2 * w // 2, ),
                  generator=get_generator(),
                  out=rd_idx)
    rd_pair_idx = idx_pair[rd_idx]
    #索引加上一定的偏移量
    rd_pair_idx += torch.arange(start=0,
                                end=n * h // 2 * w // 2 * 4,
                                step=4,
                                dtype=torch.int64,
                                device=img.device).reshape(-1, 1)
    # get masks
    mask1[rd_pair_idx[:, 0]] = 1
    mask2[rd_pair_idx[:, 1]] = 1
    return mask1, mask2

#生成图像的子图像。根据给定的图像和掩码，生成图像的子图像。
# 其中子图像是将原图像按照2*2的块进行划分，并再每个块内选择掩模为 True的像素，生成对应的子图像，
# 这样可以将图像分解成多个更小的图像块。
def generate_subimages(img, mask):
    n, c, h, w = img.shape
    #创建一个与原图像相同大小的零张量，作为子图像的容器
    subimage = torch.zeros(n,
                           c,
                           h // 2,
                           w // 2,
                           dtype=img.dtype,
                           layout=img.layout,
                           device=img.device)
    # per channel，针对每个通道进行操作
    for i in range(c):
        #将当前通道的图像通过该函数进行空间到深度的转换，得到h/2×w/2的张量
        img_per_channel = space_to_depth(img[:, i:i + 1, :, :], block_size=2)
        #对张量进行维度变换，将通道维度移动到最后，并展平为一维
        img_per_channel = img_per_channel.permute(0, 2, 3, 1).reshape(-1)
        #根据掩模mask从img_中选择相应像素，并将调整维度顺序。
        subimage[:, i:i + 1, :, :] = img_per_channel[mask].reshape(
            n, h // 2, w // 2, 1).permute(0, 3, 1, 2)
    return subimage

def calNoise(images):
    mask1, mask2 = generate_mask_pair(images)
    print("mask1.shape:{}".format(mask1.shape))
    noisy_sub1 = generate_subimages(images, mask1)
    noisy_sub2 = generate_subimages(images, mask2)
    print("noisy_sub1.shape:{}".format(noisy_sub1.shape))

    mean_filter = MeanFilter(kernel_size=5)
    denoise1 = mean_filter(noisy_sub1)
    denoise2 = mean_filter(noisy_sub2)
    print(denoise1.shape)
    print("image.shape:{}".format(images.shape))

    # 计算噪声图像和干净图像的差异
    diff1 = torch.abs(images - denoise1)
    # 根据差异计算掩码
    threshold = 0.05  # 可以根据具体情况调整阈值
    noise1 = (diff1 > threshold).float()  # 大于阈值的位置被置为 1，否则为 0
    diff2 = torch.abs(images - denoise2)
    noise2 = (diff2 > threshold).float()  # 大于阈值的位置被置为 1，否则为 0

    return noise1,noise2